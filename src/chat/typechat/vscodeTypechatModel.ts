import { PromptSection, Result, TypeChatLanguageModel, error, success } from "typechat";
import * as vscode from "vscode";
import { AgentRequest } from "../agent";
import { getResponseAsStringCopilotInteraction } from "../copilotInteractions";

export type CopilotInteractionResult = { copilotResponded: true, copilotResponse: string } | { copilotResponded: false, copilotResponse: undefined };

/**
 * @param request Original user prompt and its context.
 */
export function getTypeChatLanguageModel(request: AgentRequest): TypeChatLanguageModel {
    // TypeChat doesn't use the system prompt so leave it blank.
    const systemPrompt = "";
    const command = request.command;
    // @todo: Pull the name and the id of the extension
    const participant = { extensionId: "", name: "" };
    return {
        // Before calling TypeChat, we have already summarized the conversation history including the latest user prompt.
        // TypeChat will call this function with a further augmented user prompt and optionally assistant prompts if it needs to repair the response.
        // If there are multiple prompts, the first prompt would be earliest prompt and the prompts be interleaving user prompts and assistance prompts.
        // e.g. [1st_user_prompt, 1st_assistance_prompt, 2nd_user_prompt]
        async complete(prompt: string | PromptSection[]): Promise<Result<string>> {
            let newRequest: AgentRequest;
            console.log("Prompt generated by TypeChat", prompt);

            if (typeof prompt === "string") {
                newRequest = {
                    ...request,
                    userPrompt: prompt,
                    context: {
                        history: []
                    }
                };
            } else {
                const userPrompt = prompt.at(prompt.length - 1);
                const historyPrompts = (prompt.length > 1 ? prompt.slice(0, prompt.length - 1) : []);
                const historyTurns = historyPrompts.map((prompt) => {
                    if (prompt.role === "user") {
                        const requestTurn: vscode.ChatRequestTurn = { prompt: prompt.content, command, variables: [], participant };
                        return requestTurn;
                    } else if (prompt.role === "assistant") {
                        const response = [{
                            value: new vscode.MarkdownString(prompt.content)
                        }];
                        const responseTurn: vscode.ChatResponseTurn = {
                            response: response, result: {}, participant, command
                        };
                        return responseTurn;
                    } else {
                        return undefined;
                    }
                }).filter((turn): turn is (vscode.ChatRequestTurn | vscode.ChatResponseTurn) => !!turn);
                newRequest = {
                    ...request,
                    // userPrompt.content should never be empty but handle it just in case
                    userPrompt: userPrompt?.content ?? "",
                    context: {
                        history: historyTurns
                    }
                };
            }
            console.log("NewRequest forged for TypeChat", newRequest);
            const result = await getResponseAsStringCopilotInteraction(systemPrompt, newRequest);
            if (!!result) {
                return success(result);
            } else {
                return error("Failed to complete prompt.");
            }
        }
    };
}

export const typeChatLanguageModel: TypeChatLanguageModel = {
    async complete(prompt: string | PromptSection[]): Promise<Result<string>> {
        let messages;
        if (typeof prompt === "string") {
            messages = [
                new vscode.LanguageModelChatUserMessage(prompt)
            ];
        } else {
            messages = prompt.map((section) => {
                if (section.role === "user") {
                    return new vscode.LanguageModelChatUserMessage(section.content);
                } else if (section.role === "system") {
                    return new vscode.LanguageModelChatSystemMessage(section.content);
                } else {
                    return new vscode.LanguageModelChatAssistantMessage(section.content);
                }
            });
        }
        const cancellationTokenSource = new vscode.CancellationTokenSource();
        try {
            const response = await vscode.lm.sendChatRequest(
                "copilot-gpt-4",
                messages,
                {},
                cancellationTokenSource.token
            );
            let responseText = "";
            for await (const fragment of response.stream) {
                responseText += fragment;
            }
            return success(responseText);
        } catch (errorThrown: unknown) {
            return error("Failed to complete prompt.");
        }
    }
}
